# Uniformity Test Pass/Fail Classifier

[![View Full Report](https://img.shields.io/badge/ðŸ“Š_View_Full_Report-Documentation-blue?style=for-the-badge)](https://steinerhunter.github.io/uniformity-classifier/)

A machine learning pipeline for classifying GE HealthCare scanner uniformity tests as PASS or FAIL.

> **Note:** The test images are not included in this repository. You will need to add your own DICOM images to the `data/` directory (see Data Setup below).

## Quick Start

```bash
# 1. Clone the repository
git clone https://github.com/steinerhunter/uniformity-classifier.git
cd uniformity-classifier

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Add your data (see Data Setup below)

# 5. Set OpenAI API key (for advanced model)
export OPENAI_API_KEY=your_api_key_here

# 6. Run the pipeline
python main.py
```

## Data Setup

Place your data in the `data/` directory with this structure:

```
data/
â”œâ”€â”€ PASS/
â”‚   â”œâ”€â”€ image_001.dcm (or .png/.jpg)
â”‚   â”œâ”€â”€ image_002.dcm
â”‚   â””â”€â”€ ...
â””â”€â”€ FAIL/
    â”œâ”€â”€ image_003.dcm
    â”œâ”€â”€ image_004.dcm
    â””â”€â”€ ...
```

The pipeline supports both DICOM (`.dcm`) and standard image formats (`.png`, `.jpg`).

## Command Line Options

```bash
python main.py --help

Usage: python main.py [OPTIONS]

Options:
  --data-dir PATH      Directory containing PASS/ and FAIL/ subdirs (default: ./data)
  --output-dir PATH    Directory for output files (default: ./outputs)
  --cache-dir PATH     Directory for API response cache (default: ./cache)
  --test-size FLOAT    Fraction of data for testing (default: 0.2)
  --random-state INT   Random seed for reproducibility (default: 42)
  --no-advanced        Skip the GPT-4o model (baseline only)
  --verbose, -v        Enable debug logging

Examples:
  python main.py                              # Run with defaults
  python main.py --data-dir ./custom_data     # Custom data directory
  python main.py --test-size 0.3              # 30% test split
  python main.py --no-advanced                # Skip GPT-4o (faster)
  python main.py --verbose                    # Debug output
```

## Project Structure

```
uniformity-classifier/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ REPORT.md                 # Summary report (1-2 pages)
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ main.py                   # Entry point - runs full pipeline
â”œâ”€â”€ data/                     # Your dataset (not committed)
â”‚   â”œâ”€â”€ PASS/
â”‚   â””â”€â”€ FAIL/
â”œâ”€â”€ cache/                    # Cached GPT-4o responses (for offline mode)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py        # Load and split dataset
â”‚   â”œâ”€â”€ features.py           # Feature extraction for baseline
â”‚   â”œâ”€â”€ baseline.py           # Random Forest classifier
â”‚   â”œâ”€â”€ advanced.py           # GPT-4o vision classifier
â”‚   â””â”€â”€ evaluate.py           # Metrics, comparison, visualization
â”œâ”€â”€ tests/                    # Unit tests (39 tests)
â”‚   â”œâ”€â”€ test_data_loader.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â””â”€â”€ test_evaluate.py
â””â”€â”€ outputs/                  # Generated results
    â”œâ”€â”€ sample_images.png
    â”œâ”€â”€ confusion_matrix_baseline.png
    â”œâ”€â”€ confusion_matrix_advanced.png
    â”œâ”€â”€ per_image_results.csv
    â””â”€â”€ results.json
```

## Models

### Baseline: Random Forest on Hand-Crafted Features

Extracts 8 interpretable image quality metrics:

| Feature | Description |
|---------|-------------|
| `mean_intensity` | Average pixel brightness |
| `std_intensity` | Standard deviation of pixel values |
| `coef_of_variation` | Normalized variability (std/mean) |
| `gradient_magnitude` | Edge/transition detection via Sobel |
| `max_local_variance` | Artifact hotspot detection |
| `histogram_entropy` | Pixel distribution spread |
| `percentile_range` | Robust spread measure (p95-p5) |
| `center_vs_edge_ratio` | Vignetting detection |

### Advanced: GPT-4o Vision

Uses OpenAI's multimodal LLM to analyze images with natural language reasoning.
Provides interpretable explanations for each classification.

## Outputs

After running `python main.py`, you'll find:

| File | Description |
|------|-------------|
| `sample_images.png` | Visualization of PASS vs FAIL examples |
| `confusion_matrix_baseline.png` | Baseline model confusion matrix |
| `confusion_matrix_advanced.png` | GPT-4o model confusion matrix |
| `per_image_results.csv` | Per-image breakdown with predictions |
| `results.json` | Full metrics, feature importances, comparison |

## Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=term-missing
```

## Offline Mode

The advanced model caches all API responses in `cache/gpt4o_responses.json`.
Once you've run the pipeline, it can be reproduced without API access:

```bash
# First run - makes API calls and caches
python main.py

# Subsequent runs - uses cache
python main.py  # No API calls needed
```

## Requirements

- Python 3.9+
- No GPU required (runs on CPU)
- ~100MB RAM

## License

This project was created as a take-home assignment for GE HealthCare.
